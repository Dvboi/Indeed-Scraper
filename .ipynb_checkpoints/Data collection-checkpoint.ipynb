{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This scraper is not able to scrape more than 4-5 pages of latest jobs(INDIA) because Indeed blocks the bot and it's against it's policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import psycopg2 as pg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# connecting to the already created jobs database\n",
    "db = pg2.connect(database=\"jobs\",user='postgres',password = 'password')\n",
    "\n",
    "# making the cursor ready\n",
    "cur = db.cursor()\n",
    "\n",
    "# making the table\n",
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS JOBS(Title TEXT,is_new TEXT,company TEXT,\n",
    "location TEXT,rating TEXT,\n",
    "when_posted TEXT,salary TEXT,\n",
    "              short_summary TEXT,long_summary TEXT)\n",
    "'''\n",
    "cur.execute(query)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(url):\n",
    "    headers = requests.utils.default_headers()\n",
    "    headers.update({'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'})                 \n",
    "    r_temp = requests.get(url,headers = headers)\n",
    "    time.sleep(3)\n",
    "    soup = bs(r_temp.content)\n",
    "    summary = soup.find(\"div\",attrs={\"id\":\"jobDescriptionText\"}).get_text(\" \").strip()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_posting(page_source):\n",
    "    soup = page_source\n",
    "    # taking each card\n",
    "    job_card = soup.find_all(\"div\",attrs={\"class\":\"jobsearch-SerpJobCard unifiedRow row result\"})\n",
    "    # scrape Job info for each card\n",
    "    for posting in job_card:\n",
    "        title = posting.find(\"h2\",attrs = {\"class\":\"title\"}).a.get_text().strip()\n",
    "        short_summary = posting.find(\"div\",attrs={\"class\":\"summary\"}).ul.get_text(\" \").strip()\n",
    "        \n",
    "        try:\n",
    "            link = posting.find(\"a\",attrs={\"target\":\"_blank\"})['href']\n",
    "            link = \"https://in.indeed.com\" + link\n",
    "            long_summary = get_summary(link)\n",
    "        except:\n",
    "            long_summary = \"Does not Exist\"\n",
    "            \n",
    "        try:\n",
    "            is_new = posting.find(\"h2\",attrs = {\"class\":\"title\"}).span.get_text().strip()\n",
    "        except:\n",
    "            is_new = \"Not Disclosed\"\n",
    "            \n",
    "        try:\n",
    "            company = posting.find(\"div\",attrs = {\"class\":\"sjcl\"}).find(\"span\",attrs={\"class\":\"company\"}).get_text().strip()\n",
    "        except:\n",
    "            company = \"Not Disclosed\"\n",
    "            \n",
    "        try:\n",
    "            location = posting.find(\"div\",attrs = {\"class\":\"sjcl\"}).find(\"span\",attrs={\"class\":\"location accessible-contrast-color-location\"}).get_text().strip()  \n",
    "        except:\n",
    "            location = \"Not Disclosed\"\n",
    "            \n",
    "        try:\n",
    "            salary = posting.find(\"span\",attrs={\"class\":\"salaryText\"}).get_text().strip()\n",
    "        except:\n",
    "            salary = \"Not Disclosed\"\n",
    "            \n",
    "        try:\n",
    "            rating = posting.find(\"div\",attrs = {\"class\":\"sjcl\"}).find(\"span\",attrs={\"class\":\"ratingsDisplay\"}).find(\"span\",attrs={\"class\":\"ratingsContent\"}).get_text().strip()       \n",
    "        except:\n",
    "            rating = \"Not Available\"\n",
    "            \n",
    "        try:\n",
    "            when_posted = posting.find(\"span\",attrs={\"class\":\"date date-a11y\"}).get_text().strip()\n",
    "        except:\n",
    "            when_posted = \"Not Availble\"\n",
    "        \n",
    "        # putting to database\n",
    "        # REMEMBER TO USE PREPARED STATEMENTS WITH EXECUTION TO AVOID SQL INJECTION ATTACKS, something which we're not doing here. \n",
    "        \n",
    "        post = (title,is_new,company,location,rating,when_posted,salary,short_summary,long_summary)\n",
    "    \n",
    "        try:\n",
    "            query = \"INSERT INTO jobs VALUES('%s','%s','%s','%s','%s','%s','%s','%s','%s')\" % post\n",
    "            cur.execute(query)\n",
    "            db.commit()\n",
    "        except:\n",
    "            db.rollback()  # rolling back the transaction in case of any errors\n",
    "            \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing More to Fetch !!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://in.indeed.com/jobs?q=data%20analyst&sort=date\"\n",
    "r = requests.get(url) \n",
    "page_source = bs(r.content)\n",
    "# for first page\n",
    "scrape_posting(page_source)\n",
    "# print(page_source)\n",
    "# for the pages after that\n",
    "# k = 1  # FOR DEBUGGING\n",
    "while True:\n",
    "    try:\n",
    "        time.sleep(5)\n",
    "        link = page_source.find(\"a\",attrs={\"aria-label\":\"Next\"})\n",
    "        url = \"https://in.indeed.com\"+link[\"href\"]\n",
    "        headers = requests.utils.default_headers()\n",
    "        headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "        })\n",
    "\n",
    "        r = requests.get(url,headers=headers) \n",
    "        page_source = bs(r.content)\n",
    "        scrape_posting(page_source)\n",
    "#         k += 1 # FOR DEBUGGING\n",
    "    except:\n",
    "        print(\"Nothing More to Fetch !!\")\n",
    "        break\n",
    "#     if k==2:# FOR DEBUGGING\n",
    "#         break\n",
    "db.close() # closing database connection\n",
    "#    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DON'T RUN THESE CELLS, THEY ARE FOR CHECKING DATABASE CONNECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = pg2.connect(database=\"jobs\",user='postgres',password = 'password')\n",
    "\n",
    "# # making the cursor ready\n",
    "# cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = 'a'\n",
    "# is_new = 'f'\n",
    "# company = 'd'\n",
    "# location = \"hello world\"\n",
    "# rating = \"hello world\"\n",
    "# when_posted = \"hello world\"\n",
    "# salary = \"hello world\"\n",
    "# short_summary = \"hello world\"\n",
    "# long = \"a very long sentence as comapred to others\"\n",
    "# # {},{},{},{},{},{},{},{},{}\n",
    "# post = (title,is_new,company,location,rating,when_posted,salary,short_summary,long)\n",
    "# query = \"INSERT INTO jobs VALUES('%s','%s','%s','%s','%s','%s','%s','%s','%s')\" % post\n",
    "# cur.execute(query)\n",
    "# db.commit()\n",
    "# db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
